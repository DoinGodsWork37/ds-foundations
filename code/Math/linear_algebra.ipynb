{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Basics\n",
    "\n",
    "![matrix](imgs/matrix.png)\n",
    "![notation](imgs/notation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1402  191]\n",
      " [1371  821]\n",
      " [ 949 1437]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(\n",
    "    [[1402,191],\n",
    "     [1371,821],\n",
    "     [949,1437]]\n",
    ")\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1402"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Addition & Subtraction\n",
    "\n",
    "![add](imgs/add.png)\n",
    "![add 2](imgs/subtract.png)\n",
    "\n",
    "A Matrix is a 2D array that stores real or complex numbers. A Real Matrix is one such that all its elements r belong to ℝ. Likewise, a Complex Matrix has entries c in ℂ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix1 = np.array(\n",
    "    [[0, 4],\n",
    "     [2, 0]]\n",
    ")\n",
    "\n",
    "matrix2 = np.array(\n",
    "    [[-1, 2],\n",
    "     [1, -2]]\n",
    ")\n",
    "\n",
    "matrix_sum = matrix1 + matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  6],\n",
       "       [ 3, -2]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar Multiplication & Division\n",
    "\n",
    "![scalar](imgs/scalar.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4206,  573],\n",
       "       [4113, 2463],\n",
       "       [2847, 4311]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 467.33333333,   63.66666667],\n",
       "       [ 457.        ,  273.66666667],\n",
       "       [ 316.33333333,  479.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "![multiplication](imgs/mult_1.png)\n",
    "![multiplication](imgs/mult_2.png)\n",
    "![multiplication](imgs/mult_3.png)\n",
    "\n",
    "How to find the product of two matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix1 = np.array(\n",
    "    [[1, 4],\n",
    "     [2, 0]]\n",
    ")\n",
    "\n",
    "matrix2 = np.array(\n",
    "    [[-1, 2],\n",
    "     [1, -2]]\n",
    ")\n",
    "\n",
    "matrix_prod = np.dot(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, -6],\n",
       "       [-2,  4]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication is not communative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, -4],\n",
       "       [-3,  4]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_prod_2 = np.dot(matrix2, matrix1)\n",
    "matrix_prod_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Matrix\n",
    "\n",
    "![identity](imgs/identity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(3, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that for any matrix A, AI=IA=A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2, 1],\n",
       "       [4, 8, 3],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array(\n",
    "    [[4,2,1],\n",
    "     [4,8,3],\n",
    "     [1,1,0]]\n",
    ")\n",
    "\n",
    "I = np.identity(3, dtype=int)\n",
    "np.dot(A,I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2, 1],\n",
       "       [4, 8, 3],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A,I) == np.dot(I,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A,I) == A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposing a Matrix\n",
    "\n",
    "At times it is useful to pivot a matrix for conformability - that is in order to divide or multiply a matrix, we need to switch the rows and column dimensions of matrices.\n",
    "\n",
    "![transpose](imgs/transpose.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "\n",
      "The Transpose of A is\n",
      "[[0 2 4]\n",
      " [1 3 5]]\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(6).reshape((3,2))\n",
    "\n",
    "print(\"A is\")\n",
    "print(A)\n",
    "print(\"\")\n",
    "\n",
    "print(\"The Transpose of A is\")\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Inverting a Matrix\n",
    "\n",
    "AB = BA = I\n",
    "\n",
    "Matrix inversion is the process of finding the matrix B that satisfies the prior equation for a given invertible matrix A. (I = the identity matrix)\n",
    "\n",
    "![inverse matrix](imgs/inverse.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = np.array(\n",
    "    [[1, 4],\n",
    "     [2, 0]]\n",
    ")\n",
    "\n",
    "inverse = np.linalg.inv(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.5  ],\n",
       "       [ 0.25 , -0.125]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A square matrix that is not invertible is called singular or degenerate. A square matrix is singular if and only if its determinant is 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Determinant\n",
    "\n",
    "\n",
    "![determinant](imgs/det_1.png)\n",
    "![determinant](imgs/det_2.png)\n",
    "![determinant](imgs/det_3.png)\n",
    "![determinant](imgs/det_4.png)\n",
    "![determinant](imgs/det_5.png)\n",
    "![determinant](imgs/det_6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = np.array(\n",
    "    [[1, 4],\n",
    "     [2, 0]]\n",
    ")\n",
    "\n",
    "det = np.linalg.det(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.9999999999999982"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing determinants for a stack of matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([ \n",
    "        [[1, 2], \n",
    "         [3, 4]], \n",
    "        \n",
    "        [[1, 2], \n",
    "         [2, 1]],\n",
    "        \n",
    "        [[1, 3],\n",
    "         [3, 1]]\n",
    "    ])\n",
    "\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2., -3., -8.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving a Linear System\n",
    "\n",
    "By hand you can do Gaussian Elimination. Solve the system of equations:\n",
    "- 3x + y = 9\n",
    "- x + 2y = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(\n",
    "    [[3,1], \n",
    "     [1,2]]\n",
    ")\n",
    "\n",
    "b = np.array(\n",
    "    [9,8]\n",
    ")\n",
    "\n",
    "x = np.linalg.solve(a, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Transformations\n",
    "\n",
    "Rn ---- > Rm\n",
    "\n",
    "![linear](linear.jpg)\n",
    "![compgraphic](computergraphic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors\n",
    "\n",
    "- [Great math formula explanation](http://www.visiondummy.com/2014/03/eigenvalues-eigenvectors/)\n",
    "- [Visual explanation of Eigenvectors and Eigenvalues](http://setosa.io/ev/eigenvectors-and-eigenvalues/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eigenvalues are -3.999999999999999 and 2.9999999999999996\n",
      "The eigenvectors are [[ 0.40824829 -0.48507125 -0.0696733 ]] and [[-0.81649658 -0.72760688 -0.41803981]]\n"
     ]
    }
   ],
   "source": [
    "# consider the matrix\n",
    "# find the determinant of the matrix - lambda\n",
    "# solve the polynomial = eigenvalues\n",
    "# solve the linear system \n",
    "\n",
    "matrix = np.matrix(\n",
    "    [[1, 2, 1],\n",
    "     [6, -1, 0],\n",
    "     [-1, -2, -1]]\n",
    ")\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eig(matrix)\n",
    "print(\"The eigenvalues are {} and {}\".format(eigvals[0], eigvals[1]))\n",
    "print(\"The eigenvectors are {} and {}\".format(eigvecs[0], eigvecs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.00000000e+00,   3.00000000e+00,   9.61673584e-17])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple words, principal component analysis is a method of extracting important variables (in form of components) from a large set of variables available in a data set. It extracts low dimensional set of features from a high dimensional data set with a motive to capture as much information as possible. With fewer variables, visualization also becomes much more meaningful. PCA is more useful when dealing with 3 or higher dimensional data.\n",
    "\n",
    "**Steps**\n",
    "1. Eigendecomposition - compute eigenvectors and eigenvalues of the covariance or correlation matrix\n",
    "2. Select Principal Components - sort eigenvalues and compute explained variance\n",
    "3. Project onto New Feature Space - visualize transformed data on new subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![component](imgs/components.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First principal component is a linear combination of original predictor variables which captures the maximum variance in the data set. It determines the direction of highest variability in the data. Larger the variability captured in first component, larger the information captured by component. No other component can have variability higher than first principal component.\n",
    "\n",
    "If the two components are uncorrelated, their directions should be orthogonal (image above). This image is based on a simulated data with 2 predictors. Notice the direction of the components, as expected they are orthogonal. This suggests the correlation b/w these components in zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenfaces\n",
    "\n",
    "So if we run principal component analysis on our faces, what we’re essentially doing is producing faces that capture most of the variance on the face, where each respective principal component is orthogonal to each other (meaning each face captures the most variance of a feature on a face). We’ll call these PCA faces “eigenfaces.”\n",
    "\n",
    "![eigenfaces](eigenface.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
